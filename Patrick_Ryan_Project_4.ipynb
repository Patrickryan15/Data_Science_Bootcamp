{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Imports</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"MsoTableGrid\" border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"1589\" style=\"width:1192.0pt;border-collapse:collapse;border:none;mso-border-alt:\n",
    " solid windowtext .5pt;mso-yfti-tbllook:1184;mso-padding-alt:0in 5.4pt 0in 5.4pt\">\n",
    " <tbody><tr style=\"mso-yfti-irow:0;mso-yfti-firstrow:yes\">\n",
    "  <td width=\"397\" valign=\"top\" style=\"width:298.0pt;border:solid windowtext 1.0pt;\n",
    "  mso-border-alt:solid windowtext .5pt;background:#D9D9D9;mso-background-themecolor:\n",
    "  background1;mso-background-themeshade:217;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\"><span style=\"color:black;mso-color-alt:windowtext\">Project</span></p>\n",
    "  </td>\n",
    "  <td width=\"397\" valign=\"top\" style=\"width:298.0pt;border:solid windowtext 1.0pt;\n",
    "  border-left:none;mso-border-left-alt:solid windowtext .5pt;mso-border-alt:\n",
    "  solid windowtext .5pt;background:#D9D9D9;mso-background-themecolor:background1;\n",
    "  mso-background-themeshade:217;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\"><span style=\"color:black;mso-color-alt:windowtext\">Developer</span></p>\n",
    "  </td>\n",
    "  <td width=\"397\" valign=\"top\" style=\"width:298.0pt;border:solid windowtext 1.0pt;\n",
    "  border-left:none;mso-border-left-alt:solid windowtext .5pt;mso-border-alt:\n",
    "  solid windowtext .5pt;background:#D9D9D9;mso-background-themecolor:background1;\n",
    "  mso-background-themeshade:217;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\"><span style=\"color:black;mso-color-alt:windowtext\">Tools</span></p>\n",
    "  </td>\n",
    "  <td width=\"397\" valign=\"top\" style=\"width:298.0pt;border:solid windowtext 1.0pt;\n",
    "  border-left:none;mso-border-left-alt:solid windowtext .5pt;mso-border-alt:\n",
    "  solid windowtext .5pt;background:#D9D9D9;mso-background-themecolor:background1;\n",
    "  mso-background-themeshade:217;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\"><span style=\"color:black;mso-color-alt:windowtext\">Version</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr style=\"mso-yfti-irow:1\">\n",
    "  <td width=\"397\" valign=\"top\" style=\"width:298.0pt;border:solid windowtext 1.0pt;\n",
    "  border-top:none;mso-border-top-alt:solid windowtext .5pt;mso-border-alt:solid windowtext .5pt;\n",
    "  padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\">Bootcamp Project 4</p>\n",
    "  </td>\n",
    "  <td width=\"397\" valign=\"top\" style=\"width:298.0pt;border-top:none;border-left:\n",
    "  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;\n",
    "  mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt;\n",
    "  mso-border-alt:solid windowtext .5pt;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\">Patrick Ryan</p>\n",
    "  </td>\n",
    "  <td width=\"397\" valign=\"top\" style=\"width:298.0pt;border-top:none;border-left:\n",
    "  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;\n",
    "  mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt;\n",
    "  mso-border-alt:solid windowtext .5pt;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\">Python 3.12</p>\n",
    "  </td>\n",
    "  <td width=\"397\" valign=\"top\" style=\"width:298.0pt;border-top:none;border-left:\n",
    "  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;\n",
    "  mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt;\n",
    "  mso-border-alt:solid windowtext .5pt;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\">1</p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr style=\"mso-yfti-irow:2\">\n",
    "  <td width=\"1589\" colspan=\"4\" valign=\"top\" style=\"width:1192.0pt;border:solid windowtext 1.0pt;\n",
    "  border-top:none;mso-border-top-alt:solid windowtext .5pt;mso-border-alt:solid windowtext .5pt;\n",
    "  background:#D9D9D9;mso-background-themecolor:background1;mso-background-themeshade:\n",
    "  217;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\"><span style=\"color:black;mso-color-alt:windowtext\">Description</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr style=\"mso-yfti-irow:3;mso-yfti-lastrow:yes\">\n",
    "  <td width=\"1589\" colspan=\"4\" valign=\"top\" style=\"width:1192.0pt;border:solid windowtext 1.0pt;\n",
    "  border-top:none;mso-border-top-alt:solid windowtext .5pt;mso-border-alt:solid windowtext .5pt;\n",
    "  padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <h1>Libraries and Modules:<o:p></o:p></h1>\n",
    "  <h2 style=\"margin-left:.5in;text-indent:-.25in;mso-list:l11 level1 lfo9;\n",
    "  tab-stops:list .5in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;\n",
    "  mso-bidi-font-size:13.0pt;font-family:Symbol;mso-fareast-font-family:Symbol;\n",
    "  mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Data\n",
    "  Handling and Computation Libraries:<o:p></o:p></h2>\n",
    "  <p class=\"MsoListParagraphCxSpFirst\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l11 level2 lfo9;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->pandas: For data manipulation.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpMiddle\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l11 level2 lfo9;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]--><span class=\"SpellE\">numpy</span>: For numerical\n",
    "  operations.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpLast\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l11 level2 lfo9;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->math: For mathematical functions.<o:p></o:p></p>\n",
    "  <h2 style=\"margin-left:.5in;text-indent:-.25in;mso-list:l11 level1 lfo9;\n",
    "  tab-stops:list .5in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;\n",
    "  mso-bidi-font-size:13.0pt;font-family:Symbol;mso-fareast-font-family:Symbol;\n",
    "  mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Machine\n",
    "  Learning and Data Preprocessing Libraries:<o:p></o:p></h2>\n",
    "  <p class=\"MsoListParagraphCxSpFirst\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l11 level2 lfo9;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->scikit-learn: For machine learning\n",
    "  functionalities, including model selection, preprocessing, and feature\n",
    "  selection.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpLast\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l11 level2 lfo9;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]--><span class=\"SpellE\">tensorflow</span>: For\n",
    "  building and training deep learning models.<o:p></o:p></p>\n",
    "  <h2 style=\"margin-left:.5in;text-indent:-.25in;mso-list:l11 level1 lfo9;\n",
    "  tab-stops:list .5in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;\n",
    "  mso-bidi-font-size:13.0pt;font-family:Symbol;mso-fareast-font-family:Symbol;\n",
    "  mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Visualization\n",
    "  Libraries:<o:p></o:p></h2>\n",
    "  <p class=\"MsoListParagraph\" style=\"margin-left:1.0in;mso-add-space:auto;\n",
    "  text-indent:-.25in;mso-list:l11 level2 lfo9;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]--><span class=\"SpellE\"><span class=\"GramE\">matplotlib.pyplot</span></span>\n",
    "  and seaborn: For data visualization.<o:p></o:p></p>\n",
    "  <h2 style=\"margin-left:.5in;text-indent:-.25in;mso-list:l11 level1 lfo9;\n",
    "  tab-stops:list .5in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;\n",
    "  mso-bidi-font-size:13.0pt;font-family:Symbol;mso-fareast-font-family:Symbol;\n",
    "  mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Deep\n",
    "  Learning and Neural Network Libraries:<o:p></o:p></h2>\n",
    "  <p class=\"MsoListParagraphCxSpFirst\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l11 level2 lfo9;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]--><span class=\"SpellE\"><span class=\"GramE\">tensorflow.keras</span></span>:\n",
    "  For building and training neural network models.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpLast\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l11 level2 lfo9;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]--><span class=\"SpellE\">keras_tuner</span>: For\n",
    "  hyperparameter tuning in <span class=\"SpellE\">Keras</span> models.<o:p></o:p></p>\n",
    "  <h1>Functions:<o:p></o:p></h1>\n",
    "  <p class=\"MsoListParagraphCxSpFirst\" style=\"text-indent:-.25in;mso-list:l1 level1 lfo14\"><!--[if !supportLists]--><span style=\"mso-bidi-font-family:Calibri;mso-bidi-theme-font:minor-latin\"><span style=\"mso-list:Ignore\">1.<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]--><span class=\"SpellE\">load_data</span>: To load\n",
    "  data into a <span class=\"SpellE\">DataFrame</span>.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpMiddle\" style=\"text-indent:-.25in;mso-list:l1 level1 lfo14\"><!--[if !supportLists]--><span style=\"mso-bidi-font-family:Calibri;mso-bidi-theme-font:minor-latin\"><span style=\"mso-list:Ignore\">2.<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]--><span class=\"SpellE\">identify_data_types</span>:\n",
    "  To categorize columns into numerical and categorical based on unique values.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpMiddle\" style=\"text-indent:-.25in;mso-list:l1 level1 lfo14\"><!--[if !supportLists]--><span style=\"mso-bidi-font-family:Calibri;mso-bidi-theme-font:minor-latin\"><span style=\"mso-list:Ignore\">3.<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]--><span class=\"SpellE\">exploratory_data_analysis</span>:\n",
    "  For conducting exploratory data analysis.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpMiddle\" style=\"text-indent:-.25in;mso-list:l1 level1 lfo14\"><!--[if !supportLists]--><span style=\"mso-bidi-font-family:Calibri;mso-bidi-theme-font:minor-latin\"><span style=\"mso-list:Ignore\">4.<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]--><span class=\"SpellE\">normalize_and_encode</span>:\n",
    "  To normalize numerical columns and encode categorical columns.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpLast\" style=\"text-indent:-.25in;mso-list:l1 level1 lfo14\"><!--[if !supportLists]--><span style=\"mso-bidi-font-family:Calibri;mso-bidi-theme-font:minor-latin\"><span style=\"mso-list:Ignore\">5.<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]--><span class=\"SpellE\">handle_missing_values</span>:\n",
    "  To handle missing values in the dataset.<o:p></o:p></p>\n",
    "  <h1>Main Workflow:<o:p></o:p></h1>\n",
    "  <h2 style=\"margin-left:.5in;text-indent:-.25in;mso-list:l2 level1 lfo15;\n",
    "  tab-stops:list .5in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;\n",
    "  mso-bidi-font-size:13.0pt;font-family:Symbol;mso-fareast-font-family:Symbol;\n",
    "  mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Setup:<o:p></o:p></h2>\n",
    "  <p class=\"MsoListParagraph\" style=\"margin-left:1.0in;mso-add-space:auto;\n",
    "  text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Configuration of logging and handling of\n",
    "  TensorFlow logging levels.<o:p></o:p></p>\n",
    "  <h2 style=\"margin-left:.5in;text-indent:-.25in;mso-list:l2 level1 lfo15;\n",
    "  tab-stops:list .5in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;\n",
    "  mso-bidi-font-size:13.0pt;font-family:Symbol;mso-fareast-font-family:Symbol;\n",
    "  mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Data\n",
    "  Loading:<o:p></o:p></h2>\n",
    "  <p class=\"MsoListParagraph\" style=\"margin-left:1.0in;mso-add-space:auto;\n",
    "  text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Reading of data from a specified source using\n",
    "  the <span class=\"SpellE\">load_data</span> function.<o:p></o:p></p>\n",
    "  <h2 style=\"margin-left:.5in;text-indent:-.25in;mso-list:l2 level1 lfo15;\n",
    "  tab-stops:list .5in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;\n",
    "  mso-bidi-font-size:13.0pt;font-family:Symbol;mso-fareast-font-family:Symbol;\n",
    "  mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Exploratory\n",
    "  Data Analysis (EDA):<o:p></o:p></h2>\n",
    "  <p class=\"MsoListParagraphCxSpFirst\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Conducted using the <span class=\"SpellE\">exploratory_data_analysis</span>\n",
    "  function.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpMiddle\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Involves analysis of both numerical and\n",
    "  categorical features in the dataset.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpLast\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Target variable analysis focused on the 'ICU'\n",
    "  column.<o:p></o:p></p>\n",
    "  <h2 style=\"margin-left:.5in;text-indent:-.25in;mso-list:l2 level1 lfo15;\n",
    "  tab-stops:list .5in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;\n",
    "  mso-bidi-font-size:13.0pt;font-family:Symbol;mso-fareast-font-family:Symbol;\n",
    "  mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Data\n",
    "  Preprocessing:<o:p></o:p></h2>\n",
    "  <p class=\"MsoListParagraphCxSpFirst\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Normalization of numerical columns and\n",
    "  encoding of categorical columns using the <span class=\"SpellE\">normalize_and_encode</span>\n",
    "  function.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpLast\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Handling of missing values in the dataset\n",
    "  through the <span class=\"SpellE\">handle_missing_values</span> function.<o:p></o:p></p>\n",
    "  <h2 style=\"margin-left:.5in;text-indent:-.25in;mso-list:l2 level1 lfo15;\n",
    "  tab-stops:list .5in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;\n",
    "  mso-bidi-font-size:13.0pt;font-family:Symbol;mso-fareast-font-family:Symbol;\n",
    "  mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Model\n",
    "  Building:<o:p></o:p></h2>\n",
    "  <p class=\"MsoListParagraphCxSpFirst\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->The script includes processes for constructing\n",
    "  machine learning models.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpMiddle\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Utilizes TensorFlow and <span class=\"SpellE\">Keras</span>\n",
    "  for creating and training deep learning models.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpLast\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Incorporates hyperparameter tuning using <span class=\"SpellE\">keras_tuner</span>.<o:p></o:p></p>\n",
    "  <h2 style=\"margin-left:.5in;text-indent:-.25in;mso-list:l2 level1 lfo15;\n",
    "  tab-stops:list .5in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;\n",
    "  mso-bidi-font-size:13.0pt;font-family:Symbol;mso-fareast-font-family:Symbol;\n",
    "  mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Model\n",
    "  Evaluation:<o:p></o:p></h2>\n",
    "  <p class=\"MsoListParagraphCxSpFirst\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Likely includes functions and steps to\n",
    "  evaluate the performance of the machine learning models.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpMiddle\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Metrics such as accuracy, precision, recall,\n",
    "  F1-score, and ROC-AUC are probably computed.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpLast\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Evaluation may also involve confusion\n",
    "  matrices, ROC curves, and other visualizations to assess model performance.<o:p></o:p></p>\n",
    "  <h2 style=\"margin-left:.5in;text-indent:-.25in;mso-list:l2 level1 lfo15;\n",
    "  tab-stops:list .5in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;\n",
    "  mso-bidi-font-size:13.0pt;font-family:Symbol;mso-fareast-font-family:Symbol;\n",
    "  mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Feature\n",
    "  Selection:<o:p></o:p></h2>\n",
    "  <p class=\"MsoListParagraph\" style=\"margin-left:1.0in;mso-add-space:auto;\n",
    "  text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Processes for feature selection or reduction\n",
    "  to improve model performance, potentially using methods like PCA, RFE, or\n",
    "  others.<o:p></o:p></p>\n",
    "  <h2 style=\"margin-left:.5in;text-indent:-.25in;mso-list:l2 level1 lfo15;\n",
    "  tab-stops:list .5in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;\n",
    "  mso-bidi-font-size:13.0pt;font-family:Symbol;mso-fareast-font-family:Symbol;\n",
    "  mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Hyperparameter\n",
    "  Tuning:<o:p></o:p></h2>\n",
    "  <p class=\"MsoListParagraph\" style=\"margin-left:1.0in;mso-add-space:auto;\n",
    "  text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]--><span class=\"SpellE\">keras_tuner</span> is used\n",
    "  for hyperparameter tuning of neural network models, aiming to find the best\n",
    "  model performance.<o:p></o:p></p>\n",
    "  <h2 style=\"margin-left:.5in;text-indent:-.25in;mso-list:l2 level1 lfo15;\n",
    "  tab-stops:list .5in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;\n",
    "  mso-bidi-font-size:13.0pt;font-family:Symbol;mso-fareast-font-family:Symbol;\n",
    "  mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Additional\n",
    "  Functionalities:<o:p></o:p></h2>\n",
    "  <p class=\"MsoListParagraphCxSpFirst\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->May include data augmentation, advanced\n",
    "  preprocessing techniques, or custom loss functions for deep learning models.<o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraphCxSpLast\" style=\"margin-left:1.0in;mso-add-space:\n",
    "  auto;text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Logging and debugging practices to track the\n",
    "  script's execution and performance.<o:p></o:p></p>\n",
    "  <h2 style=\"margin-left:.5in;text-indent:-.25in;mso-list:l2 level1 lfo15;\n",
    "  tab-stops:list .5in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;\n",
    "  mso-bidi-font-size:13.0pt;font-family:Symbol;mso-fareast-font-family:Symbol;\n",
    "  mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Custom\n",
    "  Functions:<o:p></o:p></h2>\n",
    "  <p class=\"MsoListParagraph\" style=\"margin-left:1.0in;mso-add-space:auto;\n",
    "  text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Besides the ones mentioned, there might be\n",
    "  additional utility functions for data transformation, feature engineering, or\n",
    "  model diagnostics.<o:p></o:p></p>\n",
    "  <h2 style=\"margin-left:.5in;text-indent:-.25in;mso-list:l2 level1 lfo15;\n",
    "  tab-stops:list .5in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;\n",
    "  mso-bidi-font-size:13.0pt;font-family:Symbol;mso-fareast-font-family:Symbol;\n",
    "  mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Utilities\n",
    "  and Helpers:<o:p></o:p></h2>\n",
    "  <p class=\"MsoListParagraph\" style=\"margin-left:1.0in;mso-add-space:auto;\n",
    "  text-indent:-.25in;mso-list:l2 level2 lfo15;tab-stops:list 1.0in\"><!--[if !supportLists]--><span style=\"font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;\n",
    "  mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol\"><span style=\"mso-list:Ignore\">·<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Helper classes or utilities for tasks like\n",
    "  data loading, data splitting, or handling specific data types, such as\n",
    "  time-series.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\" style=\"margin-left:.5in\"><o:p>&nbsp;</o:p></p>\n",
    "  </td>\n",
    " </tr>\n",
    "</tbody></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data manipulation and numerical operations\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical operations\n",
    "\n",
    "# Logging and utilities\n",
    "import logging  # For logging information during execution\n",
    "import math  # For basic mathematical operations\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt  # For plotting graphs and charts\n",
    "import seaborn as sns  # For making statistical graphics\n",
    "\n",
    "# Machine Learning - Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder  # For feature scaling and encoding categorical variables\n",
    "from sklearn.compose import ColumnTransformer  # For applying transformers to columns of Pandas dataframes\n",
    "\n",
    "# Machine Learning - Model Selection and Validation\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into training and testing sets\n",
    "from sklearn.model_selection import KFold  # For K-Folds cross-validator\n",
    "\n",
    "# Machine Learning - Metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score  # For evaluating model performance\n",
    "\n",
    "# Machine Learning - Models\n",
    "from sklearn.ensemble import RandomForestClassifier  # For the Random Forest algorithm\n",
    "from sklearn.feature_selection import SelectFromModel  # For feature selection based on importance weights\n",
    "\n",
    "# Deep Learning with TensorFlow and Keras\n",
    "import tensorflow as tf  # For deep learning models\n",
    "from tensorflow.keras.models import Sequential  # For linear stack of layers in neural networks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten, Dropout  # Different types of neural network layers\n",
    "from tensorflow.keras.optimizers import Adam  # Optimizer for training neural networks\n",
    "from tensorflow.keras import regularizers  # Regularizers to prevent overfitting\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler  # Callbacks for better control over model training\n",
    "from keras_tuner.tuners import Hyperband # Tuner for hyperparameter optimization\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters # To manage hyperparameters for tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logging</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Function Declarations</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file into a pandas DataFrame.\n",
    "\n",
    "    This function attempts to read a CSV file specified by the 'data' parameter. \n",
    "    It includes error handling to manage situations where the file is not found, \n",
    "    the data is empty, or there's a parsing error.\n",
    "\n",
    "    Parameters:\n",
    "    data (str): The file path of the CSV file to be loaded.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the data from the CSV file.\n",
    "\n",
    "    Raises:\n",
    "    FileNotFoundError: If the CSV file is not found at the specified path.\n",
    "    pd.errors.EmptyDataError: If the CSV file is empty.\n",
    "    pd.errors.ParserError: If there is an error parsing the CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(data)  # Attempt to read the CSV file into a pandas DataFrame\n",
    "    except (FileNotFoundError, pd.errors.EmptyDataError, pd.errors.ParserError) as e:\n",
    "        logging.error(f\"Error: {str(e)}.\")  # Log the error\n",
    "        exit(1)  # Exit the program if an error occurs\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_data_types(df, unique_value_threshold=10):\n",
    "    \"\"\"\n",
    "    Identify the data types of columns in a DataFrame as either numerical or categorical.\n",
    "\n",
    "    This function iterates through each column of the DataFrame. It classifies columns \n",
    "    as 'categorical' if they are of object type or if the number of unique values \n",
    "    is less than or equal to the specified threshold. All other columns are classified as 'numerical'.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame whose columns are to be classified.\n",
    "    unique_value_threshold (int, optional): The threshold for determining if a column with numerical \n",
    "                                            values should be treated as categorical. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two lists: the first list contains the names of numerical columns, \n",
    "           and the second list contains the names of categorical columns.\n",
    "    \"\"\"\n",
    "    numerical_columns = []  # Initialize a list to store names of numerical columns\n",
    "    categorical_columns = []  # Initialize a list to store names of categorical columns\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            # Add column to categorical list if it's of object type\n",
    "            categorical_columns.append(column)\n",
    "        else:\n",
    "            # If the number of unique values is less than or equal to the threshold, consider it categorical\n",
    "            if df[column].nunique() <= unique_value_threshold:\n",
    "                categorical_columns.append(column)\n",
    "            else:\n",
    "                # Otherwise, consider it a numerical column\n",
    "                numerical_columns.append(column)\n",
    "                \n",
    "    return numerical_columns, categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploratory_data_analysis(dataframe, numerical_columns, categorical_columns, target_column='ICU', num_features=16):\n",
    "    \"\"\"\n",
    "    Perform exploratory data analysis (EDA) on a given DataFrame.\n",
    "\n",
    "    This function conducts a series of analyses, including feature correlation analysis, descriptive statistics,\n",
    "    missing values analysis, and distribution analysis. It focuses on both numerical and categorical features,\n",
    "    particularly highlighting those most correlated with a specified target column. The function visualizes\n",
    "    the distribution of the top numerical features and the percentage of missing values in them.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The DataFrame to analyze.\n",
    "    numerical_columns (list): A list of names of numerical columns in the DataFrame.\n",
    "    categorical_columns (list): A list of names of categorical columns in the DataFrame.\n",
    "    target_column (str, optional): The name of the target column for correlation analysis. Defaults to 'ICU'.\n",
    "    num_features (int, optional): The number of top features to consider for analysis. Defaults to 16.\n",
    "\n",
    "    Outputs:\n",
    "    - Prints the top features correlated with the target column.\n",
    "    - Prints descriptive statistics for the top numerical columns.\n",
    "    - Prints an analysis of missing values for the top features.\n",
    "    - Displays bar plots for missing values percentage and histograms for the distribution of top numerical features.\n",
    "\n",
    "    Returns:\n",
    "    None: This function does not return any value.\n",
    "    \"\"\"\n",
    "    # Feature Correlation Analysis: Determine the correlation of each numerical feature with the target column\n",
    "    correlation = dataframe[numerical_columns].corrwith(dataframe[target_column]).abs()\n",
    "    top_features = correlation.sort_values(ascending=False).head(num_features).index.tolist()\n",
    "    print(f\"Top {num_features} features correlated with {target_column}: {top_features}\")\n",
    "\n",
    "    # Descriptive Statistics: Provide summary statistics for the top correlated numerical features\n",
    "    print(\"\\nDescriptive Statistics for Top Numerical Columns:\\n\", dataframe[top_features].describe())\n",
    "\n",
    "    # Missing Values Analysis: Calculate and display the number and percentage of missing values in the top features\n",
    "    missing_values = dataframe[top_features].isna().sum()\n",
    "    missing_percentage = (missing_values / len(dataframe)) * 100\n",
    "    missing_df = pd.DataFrame({'Number of Missing Values': missing_values, 'Percentage': missing_percentage})\n",
    "    print(\"\\nMissing Values Analysis for Top Features:\\n\", missing_df)\n",
    "\n",
    "    # Visualization of Missing Values: Create a bar plot to visualize the percentage of missing values in top features\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=missing_df.index, y=missing_df['Percentage'])\n",
    "    plt.xticks(rotation=90)  # Rotating the feature names\n",
    "    plt.title(\"Missing Values Percentage for Top Features\")\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Percentage of Missing Values\")\n",
    "    plt.show()\n",
    "\n",
    "    # Distribution Analysis for top numerical columns: Plot histograms to visualize the distribution of top numerical features\n",
    "    top_numerical_features = [col for col in top_features if col in numerical_columns]\n",
    "    if top_numerical_features:\n",
    "        # Determine the size of the grid for plotting histograms\n",
    "        grid_size_num = int(math.ceil(math.sqrt(len(top_numerical_features))))\n",
    "        fig, axes = plt.subplots(grid_size_num, grid_size_num, figsize=(15, 15))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        # Plotting histogram for each numerical feature\n",
    "        for i, col in enumerate(top_numerical_features):\n",
    "            sns.histplot(dataframe[col], kde=True, bins=30, ax=axes[i])\n",
    "            axes[i].set_title(f\"Distribution of {col}\", fontsize=10)  # Title for each subplot\n",
    "            axes[i].set_xlabel('')  # Clearing x-labels for neatness\n",
    "            axes[i].set_ylabel('')  # Clearing y-labels for neatness\n",
    "\n",
    "        # Removing any extra subplots that are not used\n",
    "        for ax in axes[i+1:]:\n",
    "            ax.remove()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_encode(df, numerical_cols, categorical_cols):\n",
    "    \"\"\"\n",
    "    Normalize numerical columns and encode categorical columns in a DataFrame.\n",
    "\n",
    "    This function applies standard scaling to numerical columns and one-hot encoding to categorical columns.\n",
    "    It combines these transformed columns into a single DataFrame, which is suitable for machine learning models.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to be transformed.\n",
    "    numerical_cols (list): A list of names of numerical columns to be normalized.\n",
    "    categorical_cols (list): A list of names of categorical columns to be encoded.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with normalized numerical columns and one-hot encoded categorical columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the transformations for numerical and categorical columns\n",
    "    numerical_transformer = StandardScaler()  # StandardScaler for normalizing numerical data\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)  # OneHotEncoder for encoding categorical data\n",
    "\n",
    "    # Create the column transformer with specified transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ])\n",
    "\n",
    "    # Fit the transformer to the data and then transform it\n",
    "    df_transformed = preprocessor.fit_transform(df)\n",
    "\n",
    "    # Get feature names after one-hot encoding\n",
    "    one_hot_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "    all_feature_names = numerical_cols + list(one_hot_feature_names) # Combine numerical and encoded categorical feature names\n",
    "    \n",
    "    # Create a new DataFrame with the transformed data\n",
    "    df_transformed = pd.DataFrame(df_transformed, columns=all_feature_names)  # Assign column names to the transformed DataFrame\n",
    "\n",
    "    return df_transformed  # Return the transformed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "    \"\"\"\n",
    "    Handle missing values in a DataFrame.\n",
    "\n",
    "    This function creates indicators for missing data, applies forward fill imputation, and combines\n",
    "    the imputed data with the missingness indicators. Forward fill is used first, followed by backward fill\n",
    "    to address any remaining missing values.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame with missing values to handle.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame where missing values have been imputed, and missingness indicators have been added.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create missingness indicators for each column\n",
    "    missing_indicators = df.isna().astype(int).add_suffix('_missing')  # 1 indicates missing, 0 otherwise\n",
    "\n",
    "    # Apply forward fill imputation (filling the missing value with the previous value in the column)\n",
    "    df_imputed = df.fillna(method='ffill')  # Forward fill\n",
    "    df_imputed.fillna(method='bfill', inplace=True)  # Backward fill for any remaining missing values\n",
    "\n",
    "    # Combine imputed data with missingness indicators\n",
    "    df_combined = pd.concat([df_imputed, missing_indicators], axis=1)  # Add indicators to the DataFrame\n",
    "\n",
    "    return df_combined  # Return the combined DataFrame with imputed values and indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_columns(df_no_missing, df):\n",
    "    \"\"\"\n",
    "    Add missing columns 'PATIENT_VISIT_IDENTIFIER', 'ICU', and 'WINDOW' to the DataFrame if they are not present.\n",
    "\n",
    "    Args:\n",
    "        df_no_missing (pd.DataFrame): The DataFrame without missing columns.\n",
    "        df (pd.DataFrame): The original DataFrame containing the missing columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated DataFrame with missing columns added.\n",
    "    \"\"\"\n",
    "    # Check if 'PATIENT_VISIT_IDENTIFIER' is missing and add it if needed\n",
    "    if 'PATIENT_VISIT_IDENTIFIER' not in df_no_missing.columns:\n",
    "        df_no_missing['PATIENT_VISIT_IDENTIFIER'] = df['PATIENT_VISIT_IDENTIFIER']\n",
    "    \n",
    "    # Check if 'ICU' is missing and add it if needed\n",
    "    if 'ICU' not in df_no_missing.columns:\n",
    "        df_no_missing['ICU'] = df['ICU']\n",
    "    \n",
    "    # Check if 'WINDOW' is missing and add it if needed\n",
    "    if 'WINDOW' not in df_no_missing.columns:\n",
    "        df_no_missing['WINDOW'] = df['WINDOW']\n",
    "    \n",
    "    return df_no_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df, target_column='ICU', threshold=0.007, additional_cols=['PATIENT_VISIT_IDENTIFIER', 'WINDOW']):\n",
    "    \"\"\"\n",
    "    Perform feature selection on a DataFrame based on feature importance using a RandomForestClassifier.\n",
    "\n",
    "    This function handles missing values, separates the target variable and additional specified columns,\n",
    "    encodes categorical variables, and uses a RandomForestClassifier to determine feature importance. \n",
    "    Features above a specified importance threshold are selected.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to perform feature selection on.\n",
    "    target_column (str, optional): The target variable for the classification. Defaults to 'ICU'.\n",
    "    threshold (float, optional): The threshold for feature importance. Defaults to 0.007.\n",
    "    additional_cols (list, optional): Additional columns to retain in the final DataFrame. Defaults to ['PATIENT_VISIT_IDENTIFIER', 'WINDOW'].\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the DataFrame with selected features and a list of the selected feature names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Handling missing values - consider modifying this as per your dataset's requirements\n",
    "    df = df.dropna()  # Dropping rows with missing values\n",
    "\n",
    "    # Separating the target variable\n",
    "    y = df[target_column]  # Extract the target column\n",
    "\n",
    "    # Separating the additional columns to retain them later\n",
    "    additional_data = df[additional_cols]  # Extract additional columns\n",
    "\n",
    "    # Dropping the target and additional columns from the main DataFrame\n",
    "    df = df.drop(additional_cols + [target_column], axis=1, errors='ignore')  # Remove non-feature columns\n",
    "\n",
    "    # Encoding categorical variables if any\n",
    "    df_encoded = pd.get_dummies(df, drop_first=True)  # One-hot encode categorical variables\n",
    "\n",
    "    # Using RandomForestClassifier for feature importance\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(df_encoded, y)  # Train the model\n",
    "\n",
    "    # Selecting features based on importance\n",
    "    sfm = SelectFromModel(model, threshold=threshold) # Initialize the feature selector with the model\n",
    "    sfm.fit(df_encoded, y) # Fit the feature selector to the data\n",
    "    \n",
    "    # Getting the names of selected features\n",
    "    feature_names = df_encoded.columns[sfm.get_support()]  # Extract the names of important features\n",
    "\n",
    "    # Displaying selected features and their count\n",
    "    num_selected_features = len(feature_names)\n",
    "    print(f\"Number of Selected Features: {num_selected_features}\")\n",
    "    print(\"Selected Features:\")\n",
    "    for feature in feature_names:\n",
    "        print(feature)\n",
    "\n",
    "    # Creating a DataFrame with selected features and additional columns\n",
    "    df_selected = df_encoded[feature_names].join(additional_data).join(y)  # Combine selected features with additional data and the target column\n",
    "\n",
    "    return df_selected, feature_names  # Return the DataFrame with selected features and the list of feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence_data(df, patient_identifier_col, target_col, window_col):\n",
    "    \"\"\"\n",
    "    Prepare sequence data from a DataFrame for sequence-based models.\n",
    "\n",
    "    This function sorts the data by patient identifier and time window, groups by patient identifier, and then\n",
    "    creates sequences of data for each patient. It accounts for the first instance of ICU admission and \n",
    "    excludes data after this instance. The function is particularly useful for time-series or sequence prediction tasks.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data.\n",
    "    patient_identifier_col (str): Column name representing the patient identifier.\n",
    "    target_col (str): Column name representing the target variable (e.g., ICU admission status).\n",
    "    window_col (str): Column name representing the time window or sequence order.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two elements, a list of sequences (X) and a list of labels (y).\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by patient identifier and time window for sequence generation\n",
    "    df_sorted = df.sort_values(by=[patient_identifier_col, window_col])\n",
    "\n",
    "    # Group the data by patient identifier\n",
    "    grouped = df_sorted.groupby(patient_identifier_col)\n",
    "    \n",
    "    X = []  # Initialize an empty list to store feature sequences\n",
    "    y = []  # Initialize an empty list to store labels (target variable values)\n",
    "\n",
    "    for _, group in grouped:\n",
    "        # Determine the first instance of ICU admission in each group\n",
    "        first_icu_admission = group[target_col].cumsum().shift(fill_value=0).eq(1)\n",
    "\n",
    "        # Exclude data points after the first ICU admission for each patient\n",
    "        group = group[~first_icu_admission]\n",
    "        \n",
    "        # Drop columns that are not features, such as identifiers and the target column\n",
    "        features = group.drop(columns=[patient_identifier_col, target_col, window_col])\n",
    "\n",
    "        # Append the sequence of features for each patient to the list X\n",
    "        X.append(features.values)\n",
    "\n",
    "        # Append the target label for each sequence to the list y\n",
    "        # Using max() ensures capturing whether the patient was ever admitted to the ICU within the window\n",
    "        y.append(group[target_col].max())\n",
    "\n",
    "    return X, y  # Return the lists of feature sequences and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_cnn_model(input_shape, num_classes, filters, kernel_size, lstm_units, dense_units, dropout_rate, learning_rate):\n",
    "    \"\"\"\n",
    "    Create a Convolutional Neural Network (CNN) followed by a Long Short-Term Memory (LSTM) model.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): The shape of the input data (e.g., (sequence_length, input_features)).\n",
    "        num_classes (int): The number of output classes.\n",
    "        filters (int): The number of filters in the convolutional layer.\n",
    "        kernel_size (int): The size of the convolutional kernel.\n",
    "        lstm_units (int): The number of units in the LSTM layer.\n",
    "        dense_units (int): The number of units in the fully connected dense layer.\n",
    "        dropout_rate (float): The dropout rate to prevent overfitting.\n",
    "        learning_rate (float): The learning rate for optimization.\n",
    "\n",
    "    Returns:\n",
    "        Sequential: A Keras Sequential model representing the CNN-LSTM architecture.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add a 1D convolutional layer with specified filters and kernel size\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=input_shape))\n",
    "    \n",
    "    # Add MaxPooling1D layer only if the input is large enough\n",
    "    if input_shape[0] > kernel_size:\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Add a Long Short-Term Memory (LSTM) layer with specified units and activation function\n",
    "    model.add(LSTM(lstm_units, activation='tanh'))\n",
    "    \n",
    "    # Flatten the output of LSTM layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Add a fully connected dense layer with specified units and ReLU activation\n",
    "    model.add(Dense(dense_units, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    \n",
    "    # Add dropout layer to prevent overfitting\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Use 'softmax' activation for multi-class classification and 'sigmoid' for binary classification\n",
    "    model.add(Dense(num_classes, activation='softmax' if num_classes > 1 else 'sigmoid'))\n",
    "    \n",
    "    # Compile the model with the specified optimizer, loss function, and metrics\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    \"\"\"\n",
    "    Learning rate schedule function to adjust learning rate during training.\n",
    "\n",
    "    Args:\n",
    "        epoch (int): The current epoch number.\n",
    "        lr (float): The current learning rate.\n",
    "\n",
    "    Returns:\n",
    "        float: The updated learning rate for the epoch.\n",
    "    \"\"\"\n",
    "    if epoch < 10:\n",
    "        return lr  # Use initial learning rate for the first 10 epochs\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)  # Adjust learning rate exponentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(input_shape, num_classes, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Tune hyperparameters for a CNN-LSTM model using Keras Tuner.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): The shape of the input data (e.g., (sequence_length, input_features)).\n",
    "        num_classes (int): The number of output classes.\n",
    "        X_train (numpy.ndarray): Training data.\n",
    "        y_train (numpy.ndarray): Training labels.\n",
    "        X_val (numpy.ndarray): Validation data.\n",
    "        y_val (numpy.ndarray): Validation labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: The best hyperparameters found during tuning.\n",
    "    \"\"\"\n",
    "    def model_builder(hp):\n",
    "        \"\"\"\n",
    "        Build a CNN-LSTM model with hyperparameters specified by the Keras Tuner.\n",
    "\n",
    "        Args:\n",
    "            hp (HyperParameters): An instance of the Keras Tuner HyperParameters class used to define hyperparameters.\n",
    "\n",
    "        Returns:\n",
    "            Sequential: A Keras Sequential model representing the CNN-LSTM architecture with hyperparameter configurations.\n",
    "        \"\"\"\n",
    "        # Define hyperparameters to be tuned\n",
    "        hp_filters = hp.Int('filters', min_value=16, max_value=64, step=16)\n",
    "        hp_kernel_size = hp.Choice('kernel_size', values=[3, 5])\n",
    "        hp_lstm_units = hp.Int('lstm_units', min_value=30, max_value=100, step=10)\n",
    "        hp_dense_units = hp.Int('dense_units', min_value=16, max_value=64, step=16)\n",
    "        hp_dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "        hp_learning_rate = hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')\n",
    "\n",
    "        # Build the model with the specified hyperparameters\n",
    "        model = create_lstm_cnn_model(input_shape, num_classes, hp_filters, hp_kernel_size, hp_lstm_units, hp_dense_units, hp_dropout_rate, hp_learning_rate)\n",
    "\n",
    "        # Use Adam optimizer with a custom learning rate\n",
    "        optimizer = Adam(learning_rate=hp_learning_rate)\n",
    "\n",
    "        # Compile the model with the custom learning rate scheduler\n",
    "        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    # Initialize a Hyperband tuner\n",
    "    tuner = Hyperband(\n",
    "        model_builder,\n",
    "        objective='val_accuracy',\n",
    "        max_epochs=50,\n",
    "        factor=5,\n",
    "        directory='my_dir',\n",
    "        project_name='lstm_cnn_tuning_hyperband')\n",
    "\n",
    "    # Define a grid search over specified hyperparameters\n",
    "    hp = HyperParameters()\n",
    "    hp.Int('filters', min_value=16, max_value=64, step=16)\n",
    "    hp.Choice('kernel_size', values=[3, 5])\n",
    "    hp.Int('lstm_units', min_value=30, max_value=100, step=10)\n",
    "    hp.Int('dense_units', min_value=16, max_value=64, step=16)\n",
    "    hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')\n",
    "\n",
    "    # Define a learning rate scheduler callback\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    # Start hyperparameter tuning\n",
    "    tuner.search(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[lr_scheduler], hyperparameters=hp)\n",
    "\n",
    "    # Get the best hyperparameters found during tuning\n",
    "    best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "    return best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(X, y, input_shape, num_classes, best_hps, n_folds=4, n_repeats=1, epochs=50, batch_size=32):\n",
    "    \"\"\"\n",
    "    Perform cross-validation for a CNN-LSTM model.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): Input data.\n",
    "        y (numpy.ndarray): Target labels.\n",
    "        input_shape (tuple): The shape of the input data (e.g., (sequence_length, input_features)).\n",
    "        num_classes (int): The number of output classes.\n",
    "        best_hps (dict): A dictionary containing the best hyperparameters found during tuning.\n",
    "        n_folds (int, optional): The number of folds for cross-validation. Default is 4.\n",
    "        n_repeats (int, optional): The number of times to repeat cross-validation. Default is 1.\n",
    "        epochs (int, optional): The number of training epochs. Default is 50.\n",
    "        batch_size (int, optional): The batch size for training. Default is 32.\n",
    "\n",
    "    Returns:\n",
    "        float: The average accuracy across all cross-validation repeats.\n",
    "    \"\"\"\n",
    "    # Initialize results list\n",
    "    all_results = []\n",
    "\n",
    "    # Repeated cross-validation\n",
    "    for _ in range(n_repeats):\n",
    "        # Define K-fold cross-validator\n",
    "        kf = KFold(n_splits=n_folds, shuffle=True, random_state=None)\n",
    "        \n",
    "        # Initialize results for this repeat\n",
    "        results = []\n",
    "\n",
    "        # K-fold cross-validation\n",
    "        for train_index, val_index in kf.split(X):\n",
    "            # Split data\n",
    "            X_train, X_val = X[train_index], X[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "            # Create and compile the model with the best hyperparameters\n",
    "            model = create_lstm_cnn_model(\n",
    "                input_shape=input_shape, \n",
    "                num_classes=num_classes, \n",
    "                filters=best_hps.get('filters'), \n",
    "                kernel_size=best_hps.get('kernel_size'), \n",
    "                lstm_units=best_hps.get('lstm_units'), \n",
    "                dense_units=best_hps.get('dense_units'), \n",
    "                dropout_rate=best_hps.get('dropout_rate'), \n",
    "                learning_rate=best_hps.get('learning_rate'))\n",
    "\n",
    "            # EarlyStopping callback\n",
    "            early_stopping_callback = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, restore_best_weights=True)\n",
    "\n",
    "            # Fit the model\n",
    "            model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[early_stopping_callback], verbose=0)\n",
    "\n",
    "            # Evaluate the model\n",
    "            loss, accuracy = model.evaluate(X_val, y_val)\n",
    "            results.append(accuracy)\n",
    "\n",
    "        # Calculate average performance for this repeat\n",
    "        average_performance = np.mean(results)\n",
    "        all_results.append(average_performance)\n",
    "\n",
    "    # Calculate average performance across all repeats\n",
    "    overall_average_performance = np.mean(all_results)\n",
    "\n",
    "    return overall_average_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, run_results):\n",
    "    \"\"\"\n",
    "    Evaluate a trained model on test data and collect performance metrics.\n",
    "\n",
    "    Args:\n",
    "        model: A trained Keras model.\n",
    "        X_test (numpy.ndarray): Test input data.\n",
    "        y_test (numpy.ndarray): Test target labels.\n",
    "        run_results (dict): A dictionary to store evaluation results.\n",
    "    \"\"\"\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1) if y_pred.shape[1] > 1 else (y_pred > 0.5).astype('int32')\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    run_results['accuracy'] = accuracy\n",
    "    # Classification report\n",
    "    report = classification_report(y_test, y_pred_classes, output_dict=True)\n",
    "    # Extract the required metrics using .get() for safer access\n",
    "    weighted_avg = report.get('weighted avg', {})\n",
    "    run_results['precision'] = weighted_avg.get('precision', None)\n",
    "    run_results['recall'] = weighted_avg.get('recall', None)\n",
    "    run_results['f1-score'] = weighted_avg.get('f1-score', None)\n",
    "    # Check if the values were successfully retrieved\n",
    "    if run_results['precision'] is None or run_results['recall'] is None or run_results['f1-score'] is None:\n",
    "        print(\"Some metrics were not found in the classification report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_val, y_val, input_shape, num_classes, best_hps, num_runs):\n",
    "    \"\"\"\n",
    "    Train a CNN-LSTM model with hyperparameters and evaluate its performance.\n",
    "\n",
    "    Args:\n",
    "        X_train (numpy.ndarray): Training input data.\n",
    "        y_train (numpy.ndarray): Training target labels.\n",
    "        X_val (numpy.ndarray): Validation input data.\n",
    "        y_val (numpy.ndarray): Validation target labels.\n",
    "        input_shape (tuple): The shape of the input data (e.g., (sequence_length, input_features)).\n",
    "        num_classes (int): The number of output classes.\n",
    "        best_hps (dict): A dictionary containing the best hyperparameters found during tuning.\n",
    "        num_runs (int): The number of training runs to perform.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the trained model and its training history.\n",
    "    \"\"\"\n",
    "    # Default values for hyperparameters\n",
    "    DEFAULT_EPOCHS = 50\n",
    "    DEFAULT_BATCH_SIZE = 32\n",
    "    DEFAULT_LEARNING_RATE = 0.001\n",
    "    DEFAULT_FILTERS = 64\n",
    "    DEFAULT_KERNEL_SIZE = 3\n",
    "    DEFAULT_LSTM_UNITS = 100\n",
    "    DEFAULT_DENSE_UNITS = 100\n",
    "    DEFAULT_DROPOUT_RATE = 0.5\n",
    "\n",
    "    average_results = []\n",
    "    for run in range(num_runs):\n",
    "        run_results = {}\n",
    "\n",
    "        # Extract hyperparameters safely with default values\n",
    "        filters = best_hps.get('filters') if 'filters' in best_hps else DEFAULT_FILTERS\n",
    "        kernel_size = best_hps.get('kernel_size') if 'kernel_size' in best_hps else DEFAULT_KERNEL_SIZE\n",
    "        lstm_units = best_hps.get('lstm_units') if 'lstm_units' in best_hps else DEFAULT_LSTM_UNITS\n",
    "        dense_units = best_hps.get('dense_units') if 'dense_units' in best_hps else DEFAULT_DENSE_UNITS\n",
    "        dropout_rate = best_hps.get('dropout_rate') if 'dropout_rate' in best_hps else DEFAULT_DROPOUT_RATE\n",
    "        learning_rate = best_hps.get('learning_rate') if 'learning_rate' in best_hps else DEFAULT_LEARNING_RATE\n",
    "        epochs = best_hps.get('epochs') if 'epochs' in best_hps else DEFAULT_EPOCHS\n",
    "        batch_size = best_hps.get('batch_size') if 'batch_size' in best_hps else DEFAULT_BATCH_SIZE\n",
    "\n",
    "        # Create the model with the hyperparameters\n",
    "        model = create_lstm_cnn_model(input_shape, num_classes, filters, kernel_size, lstm_units, dense_units, dropout_rate, learning_rate)\n",
    "\n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        # Train the model with early stopping\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                            epochs=epochs, batch_size=batch_size, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "        # After training, evaluate the model and collect results\n",
    "        evaluate_model(model, X_val, y_val, run_results)\n",
    "        \n",
    "        # Print the classification report\n",
    "        print(f\"Classification Report (Run {run + 1}):\")\n",
    "        print(classification_report(y_val, model.predict(X_val) > 0.5))  # Adjust the threshold if needed\n",
    "\n",
    "        # Append the results of this run to the average_results list\n",
    "        average_results.append(run_results)\n",
    "\n",
    "    # Calculate and print the average results across all runs\n",
    "    average_precision = sum(result['precision'] for result in average_results) / len(average_results)\n",
    "    average_recall = sum(result['recall'] for result in average_results) / len(average_results)\n",
    "    average_f1_score = sum(result['f1-score'] for result in average_results) / len(average_results)\n",
    "    average_accuracy = sum(result.get('accuracy', 0) for result in average_results) / len(average_results)\n",
    "\n",
    "    # Print average results\n",
    "    print(f'Average Precision: {average_precision:.2f}')\n",
    "    print(f'Average Recall: {average_recall:.2f}')\n",
    "    print(f'Average F1-Score: {average_f1_score:.2f}')\n",
    "    print(f'Average Accuracy: {average_accuracy:.2f}')\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Loading the dataset...\")\n",
    "    df = load_data(\"COVID-Full.csv\")\n",
    "    \n",
    "    print(\"Identifying data types...\")\n",
    "    numerical_cols, categorical_cols = identify_data_types(df)\n",
    "    \n",
    "    print(\"Performing EDA...\")\n",
    "    exploratory_data_analysis(df, numerical_cols, categorical_cols)\n",
    "    \n",
    "    print(\"Normalizing and encoding data...\")\n",
    "    df_encoded = normalize_and_encode(df, numerical_cols, categorical_cols)\n",
    "    \n",
    "    print(\"Handling missing values...\")\n",
    "    df_no_missing = handle_missing_values(df_encoded)\n",
    "    df_no_missing = add_missing_columns(df_no_missing, df)\n",
    "        \n",
    "    print(\"Performing feature selection...\")\n",
    "    df_selected, selected_features = feature_selection(df_no_missing, 'ICU')\n",
    "    \n",
    "    print(\"Preparing sequence data...\")\n",
    "    X, y = prepare_sequence_data(df_selected, 'PATIENT_VISIT_IDENTIFIER', 'ICU', 'WINDOW')\n",
    "    \n",
    "    print(\"Converting data to numpy arrays...\")\n",
    "    X_array = np.array(X, dtype=object)\n",
    "    y_array = np.array(y)\n",
    "    \n",
    "    print(\"Padding sequences...\")\n",
    "    max_sequence_length = max(len(sequence) for sequence in X_array)\n",
    "    feature_size = X_array[0].shape[1]\n",
    "    X_padded = np.array([np.pad(sequence, ((0, max_sequence_length - len(sequence)), (0, 0)), mode='constant', constant_values=0) for sequence in X_array])\n",
    "    \n",
    "    print(\"Splitting data into training and validation sets...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_padded, y_array, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(\"Determining model parameters...\")\n",
    "    input_shape = (max_sequence_length, feature_size)\n",
    "    num_classes = 1\n",
    "    \n",
    "    print(\"Performing hyperparameter tuning...\")\n",
    "    best_hps = tune_hyperparameters(input_shape, num_classes, X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    print(\"Performing K-Fold Cross-Validation...\")\n",
    "    average_accuracy = cross_validate_model(X_padded, y_array, input_shape, num_classes, best_hps, n_folds=4, epochs=50, batch_size=32)\n",
    "    \n",
    "    print(f\"Average Accuracy across folds: {average_accuracy}\")\n",
    "    \n",
    "    print(\"Training the model with best hyperparameters...\")\n",
    "    model, history = train_model(X_train, y_train, X_val, y_val, input_shape, num_classes, best_hps, num_runs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Script Start</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
