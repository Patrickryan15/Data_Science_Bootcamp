{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"WordSection1\">\n",
    "\n",
    "<h1>SCRIPT INFO </h1>\n",
    "\n",
    "<table class=\"MsoTableGrid\" border=\"1\" cellspacing=\"0\" cellpadding=\"0\" style=\"border-collapse:collapse;border:none;mso-border-alt:solid windowtext .5pt;\n",
    " mso-yfti-tbllook:1184;mso-padding-alt:0in 5.4pt 0in 5.4pt\">\n",
    " <tbody><tr style=\"mso-yfti-irow:0;mso-yfti-firstrow:yes\">\n",
    "  <td width=\"413\" valign=\"top\" style=\"width:310.0pt;border:solid windowtext 1.0pt;\n",
    "  mso-border-alt:solid windowtext .5pt;background:#B4C6E7;mso-background-themecolor:\n",
    "  accent1;mso-background-themetint:102;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\"><b><span style=\"font-size:14.0pt;color:black;mso-color-alt:windowtext\">Project</span></b><b><span style=\"font-size:14.0pt\"><o:p></o:p></span></b></p>\n",
    "  </td>\n",
    "  <td width=\"432\" valign=\"top\" style=\"width:4.5in;border:solid windowtext 1.0pt;\n",
    "  border-left:none;mso-border-left-alt:solid windowtext .5pt;mso-border-alt:\n",
    "  solid windowtext .5pt;background:#B4C6E7;mso-background-themecolor:accent1;\n",
    "  mso-background-themetint:102;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\"><b><span style=\"font-size:14.0pt;color:black;mso-color-alt:windowtext\">Developer</span></b><b><span style=\"font-size:14.0pt\"><o:p></o:p></span></b></p>\n",
    "  </td>\n",
    "  <td width=\"462\" valign=\"top\" style=\"width:346.5pt;border:solid windowtext 1.0pt;\n",
    "  border-left:none;mso-border-left-alt:solid windowtext .5pt;mso-border-alt:\n",
    "  solid windowtext .5pt;background:#B4C6E7;mso-background-themecolor:accent1;\n",
    "  mso-background-themetint:102;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\"><b><span style=\"font-size:14.0pt;color:black;mso-color-alt:windowtext\">Tools</span></b><b><span style=\"font-size:14.0pt\"><o:p></o:p></span></b></p>\n",
    "  </td>\n",
    "  <td width=\"516\" valign=\"top\" style=\"width:387.0pt;border:solid windowtext 1.0pt;\n",
    "  border-left:none;mso-border-left-alt:solid windowtext .5pt;mso-border-alt:\n",
    "  solid windowtext .5pt;background:#B4C6E7;mso-background-themecolor:accent1;\n",
    "  mso-background-themetint:102;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\"><b><span style=\"font-size:14.0pt;color:black;mso-color-alt:windowtext\">Version</span></b><b><span style=\"font-size:14.0pt\"><o:p></o:p></span></b></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr style=\"mso-yfti-irow:1\">\n",
    "  <td width=\"413\" valign=\"top\" style=\"width:310.0pt;border:solid windowtext 1.0pt;\n",
    "  border-top:none;mso-border-top-alt:solid windowtext .5pt;mso-border-alt:solid windowtext .5pt;\n",
    "  padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\">Bootcamp Project 2</p>\n",
    "  </td>\n",
    "  <td width=\"432\" valign=\"top\" style=\"width:4.5in;border-top:none;border-left:none;\n",
    "  border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;\n",
    "  mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt;\n",
    "  mso-border-alt:solid windowtext .5pt;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\">Patrick Ryan</p>\n",
    "  </td>\n",
    "  <td width=\"462\" valign=\"top\" style=\"width:346.5pt;border-top:none;border-left:\n",
    "  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;\n",
    "  mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt;\n",
    "  mso-border-alt:solid windowtext .5pt;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\">Python 3.12</p>\n",
    "  </td>\n",
    "  <td width=\"516\" valign=\"top\" style=\"width:387.0pt;border-top:none;border-left:\n",
    "  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;\n",
    "  mso-border-top-alt:solid windowtext .5pt;mso-border-left-alt:solid windowtext .5pt;\n",
    "  mso-border-alt:solid windowtext .5pt;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\">1.1</p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr style=\"mso-yfti-irow:2\">\n",
    "  <td width=\"1823\" colspan=\"4\" valign=\"top\" style=\"width:1367.5pt;border:solid windowtext 1.0pt;\n",
    "  border-top:none;mso-border-top-alt:solid windowtext .5pt;mso-border-alt:solid windowtext .5pt;\n",
    "  background:#B4C6E7;mso-background-themecolor:accent1;mso-background-themetint:\n",
    "  102;padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\" align=\"center\" style=\"text-align:center\"><b><span style=\"font-size:14.0pt;color:black;mso-color-alt:windowtext\">Description</span><o:p></o:p></b></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr style=\"mso-yfti-irow:3;mso-yfti-lastrow:yes\">\n",
    "  <td width=\"1823\" colspan=\"4\" valign=\"top\" style=\"width:1367.5pt;border:solid windowtext 1.0pt;\n",
    "  border-top:none;mso-border-top-alt:solid windowtext .5pt;mso-border-alt:solid windowtext .5pt;\n",
    "  padding:0in 5.4pt 0in 5.4pt\">\n",
    "  <p class=\"MsoNormal\"><o:p>&nbsp;</o:p></p>\n",
    "  <p class=\"MsoNormal\">This Python script is designed for machine learning tasks,\n",
    "  specifically focused on classification using the <span class=\"SpellE\">XGBoost</span>\n",
    "  algorithm. It follows a comprehensive workflow for handling various aspects\n",
    "  of the machine learning process, including data preprocessing, feature\n",
    "  engineering, handling missing values, addressing class imbalance, model\n",
    "  training, and evaluation. Below is a breakdown of the major components and\n",
    "  functionalities of the script:</p>\n",
    "  <p class=\"MsoNormal\"><o:p>&nbsp;</o:p></p>\n",
    "  <h2>Libraries and Modules:<o:p></o:p></h2>\n",
    "  <p class=\"MsoNormal\"><b>pandas</b>: For data manipulation and analysis.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><span class=\"SpellE\"><b>numpy</b></span>: For numerical\n",
    "  operations.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><b>matplotlib</b> and <b>seaborn</b>: For data\n",
    "  visualization.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><b>scikit-learn</b>: For machine learning tools, such as\n",
    "  data splitting, model evaluation, and preprocessing.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><b>imbalanced-learn</b> (<span class=\"SpellE\"><b>imblearn</b></span>):\n",
    "  For handling class imbalance.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><span class=\"SpellE\"><b>xgboost</b></span>: For implementing\n",
    "  the <span class=\"SpellE\">XGBoost</span> classifier.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><b>logging</b>: For logging informational messages.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><span class=\"SpellE\"><b>joblib</b></span>: For parallel\n",
    "  processing during feature selection.<o:p></o:p></p>\n",
    "  <h2><o:p>&nbsp;</o:p></h2>\n",
    "  <h2>Functions:<o:p></o:p></h2>\n",
    "  <p class=\"MsoNormal\"><span class=\"SpellE\"><b>extract_percentile</b></span>:\n",
    "  Extracts percentiles from the 'AGE_PERCENTIL' column.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><span class=\"SpellE\"><b>define_age_group</b></span>: Creates\n",
    "  an 'AGE_GROUP' feature based on age.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><span class=\"SpellE\"><b>handle_missing_values</b></span>:\n",
    "  Removes rows with missing values and imputes missing values in both numerical\n",
    "  and categorical columns.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><span class=\"SpellE\"><b>handle_class_imbalance</b></span>:\n",
    "  Addresses class imbalance using Synthetic Minority Over-sampling Technique\n",
    "  (SMOTE).<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><span class=\"SpellE\"><b>encode_categorical_variables</b></span>:\n",
    "  Uses one-hot encoding for categorical variables.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><span class=\"SpellE\"><b>normalize_numerical_features</b></span>:\n",
    "  Standardizes numerical features.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><span class=\"SpellE\"><b>data_exploration</b></span>:\n",
    "  Conducts exploratory data analysis.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><span class=\"SpellE\"><b>perform_grid_search</b></span>:\n",
    "  Performs grid search for hyperparameter tuning.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><span class=\"SpellE\"><b>train_model</b></span>: Trains a\n",
    "  machine learning model using <span class=\"SpellE\">XGBoost</span>.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><span class=\"SpellE\"><b>evaluate_model</b></span>: Evaluates\n",
    "  the trained model using various metrics and visualizations.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><span class=\"SpellE\"><b>identify_column_type</b></span>:\n",
    "  Identifies categorical and numerical columns in a <span class=\"SpellE\">DataFrame</span>.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><span class=\"SpellE\"><b>data_preprocessing</b></span>:\n",
    "  Applies a series of preprocessing steps to the dataset.<o:p></o:p></p>\n",
    "  <h2><o:p>&nbsp;</o:p></h2>\n",
    "  <h2>Main Workflow:<o:p></o:p></h2>\n",
    "  <p class=\"MsoNormal\"><b>Loading Data:</b><o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraph\" style=\"margin-left:1.0in;mso-add-space:auto;\n",
    "  text-indent:-.25in;mso-list:l5 level2 lfo6\"><!--[if !supportLists]--><span style=\"font-family:&quot;Courier New&quot;;mso-fareast-font-family:&quot;Courier New&quot;\"><span style=\"mso-list:Ignore\">o<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Reads the dataset from a CSV file\n",
    "  ('COVID-Full.csv').<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><b>Data Preprocessing:</b><o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraph\" style=\"margin-left:1.0in;mso-add-space:auto;\n",
    "  text-indent:-.25in;mso-list:l5 level2 lfo6\"><!--[if !supportLists]--><span style=\"font-family:&quot;Courier New&quot;;mso-fareast-font-family:&quot;Courier New&quot;\"><span style=\"mso-list:Ignore\">o<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Applies preprocessing steps, including feature\n",
    "  extraction, handling missing values, encoding categorical variables, and\n",
    "  normalizing numerical features.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><b>Feature Selection:</b><o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraph\" style=\"margin-left:1.0in;mso-add-space:auto;\n",
    "  text-indent:-.25in;mso-list:l5 level2 lfo6\"><!--[if !supportLists]--><span style=\"font-family:&quot;Courier New&quot;;mso-fareast-font-family:&quot;Courier New&quot;\"><span style=\"mso-list:Ignore\">o<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Identifies important features using Recursive\n",
    "  Feature Elimination (RFE) with <span class=\"SpellE\">XGBoost</span>.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><b>Updated Training:</b><o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraph\" style=\"margin-left:1.0in;mso-add-space:auto;\n",
    "  text-indent:-.25in;mso-list:l5 level2 lfo6\"><!--[if !supportLists]--><span style=\"font-family:&quot;Courier New&quot;;mso-fareast-font-family:&quot;Courier New&quot;\"><span style=\"mso-list:Ignore\">o<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Imputes missing values for important features\n",
    "  and retrains the <span class=\"SpellE\">XGBoost</span> model.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><b>Evaluation:</b><o:p></o:p></p>\n",
    "  <p class=\"MsoListParagraph\" style=\"margin-left:1.0in;mso-add-space:auto;\n",
    "  text-indent:-.25in;mso-list:l5 level2 lfo6\"><!--[if !supportLists]--><span style=\"font-family:&quot;Courier New&quot;;mso-fareast-font-family:&quot;Courier New&quot;\"><span style=\"mso-list:Ignore\">o<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;\n",
    "  </span></span></span><!--[endif]-->Evaluates the model on the test set, adjusting\n",
    "  the threshold and displaying metrics like accuracy, precision, recall,\n",
    "  F1-score, AUC-ROC, ROC curve, and confusion matrix.<o:p></o:p></p>\n",
    "  <h2><o:p>&nbsp;</o:p></h2>\n",
    "  <h2>Additional Information:<o:p></o:p></h2>\n",
    "  <p class=\"MsoNormal\">Uses logging for tracking information during script\n",
    "  execution.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\">Utilizes parallel processing for feature selection.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\">Provides detailed information about data cleaning,\n",
    "  handling class imbalance, and model training.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\">The script is tailored for a specific classification task\n",
    "  related to ICU admission prediction in the context of COVID-19, with a focus\n",
    "  on addressing challenges such as class imbalance and missing data.<o:p></o:p></p>\n",
    "  <p class=\"MsoNormal\"><o:p>&nbsp;</o:p></p>\n",
    "  </td>\n",
    " </tr>\n",
    "</tbody></table>\n",
    "\n",
    "<p class=\"MsoNormal\"><o:p>&nbsp;</o:p></p>\n",
    "\n",
    "<p class=\"MsoNormal\"><o:p>&nbsp;</o:p></p>\n",
    "\n",
    "<p class=\"MsoNormal\"><o:p>&nbsp;</o:p></p>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Imports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, accuracy_score, precision_score, recall_score, f1_score,\n",
    "    ConfusionMatrixDisplay, confusion_matrix, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import logging\n",
    "from joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logging</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Function Declarations</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    logging.info(\"Performing feature engineering...\")\n",
    "    # Extract percentile from 'AGE_PERCENTIL'\n",
    "    df['AGE_PERCENTIL'] = df['AGE_PERCENTIL'].apply(lambda x: 90 if 'Above' in x else int(x.replace('th', '')))\n",
    "    # Define age group based on the extracted percentile\n",
    "    df['AGE_GROUP'] = pd.cut(df['AGE_PERCENTIL'], bins=[0, 18, 35, 50, 65, np.inf], labels=['child', 'young_adult', 'middle_adult', 'older_adult', 'elderly'])\n",
    "    # Encode the 'WINDOW' column using ordinal encoding\n",
    "    ordinal_encoder = OrdinalEncoder(categories=[['0-2', '2-4', '4-6', '6-12', 'ABOVE_12']])\n",
    "    df[['WINDOW']] = ordinal_encoder.fit_transform(df[['WINDOW']])\n",
    "    # Drop the 'AGE_PERCENTIL' column if no longer needed\n",
    "    df.drop('AGE_PERCENTIL', axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, numerical_cols, important_features=None):\n",
    "    logging.info(\"Handling missing values...\")\n",
    "    original_rows = df.shape[0]  # Total number of rows in the original DataFrame\n",
    "    \n",
    "    # Check if any important features have missing values\n",
    "    if important_features:\n",
    "        logging.info(\"Removing rows with missing values for important features...\")\n",
    "        missing_cols = [col for col in important_features if col in df.columns and df[col].isnull().any()]\n",
    "        if missing_cols:\n",
    "            # Remove rows with missing values for important features\n",
    "            df_cleaned = df.dropna(subset=missing_cols)\n",
    "            remaining_rows = df_cleaned.shape[0]  # Number of rows after cleaning\n",
    "            removed_rows = original_rows - remaining_rows\n",
    "            logging.info(f\"Removed {removed_rows} rows ({(removed_rows / original_rows) * 100:.2f}%) with missing values for important features.\")\n",
    "            logging.info(f\"Percentage of data remaining: {(remaining_rows / original_rows) * 100:.2f}%\")\n",
    "        else:\n",
    "            logging.info(\"No rows with missing values for important features. DataFrame remains unchanged.\")\n",
    "            df_cleaned = df.copy()\n",
    "    else:\n",
    "        logging.info(\"Removing all rows with missing values...\")\n",
    "        df_cleaned = df.dropna()\n",
    "        remaining_rows = df_cleaned.shape[0]  # Number of rows after cleaning\n",
    "        removed_rows = original_rows - remaining_rows\n",
    "        logging.info(f\"Removed {removed_rows} rows ({(removed_rows / original_rows) * 100:.2f}%) with missing values.\")\n",
    "        logging.info(f\"Percentage of data remaining: {(remaining_rows / original_rows) * 100:.2f}%\")\n",
    "    # Convert numerical_cols to pandas Index\n",
    "    numerical_cols = pd.Index(numerical_cols)\n",
    "    # Impute missing values for numerical columns\n",
    "    if not numerical_cols.empty:\n",
    "        print(\"Imputing stuffs\")\n",
    "        imputer_numeric = SimpleImputer(strategy='median')\n",
    "        df_cleaned.loc[:, numerical_cols] = imputer_numeric.fit_transform(df_cleaned[numerical_cols])\n",
    "    # Impute missing values for categorical columns\n",
    "    for col in df_cleaned.columns:\n",
    "        if col not in numerical_cols:\n",
    "            df_cleaned.loc[:, col] = df_cleaned[col].fillna(df_cleaned[col].mode()[0])\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_class_imbalance(X_train, y_train):\n",
    "    logging.info(\"Handling class imbalance...\")\n",
    "    # Check if labels are numeric\n",
    "    if np.issubdtype(y_train.dtype, np.number):\n",
    "        # Convert to binary labels based on a threshold\n",
    "        threshold = 0.5\n",
    "        y_train_binary = (y_train > threshold).astype(int)\n",
    "        # Use SMOTE to handle class imbalance\n",
    "        smote = SMOTE(sampling_strategy='auto', random_state=42)  # 'auto' adjusts the strategy based on the input data\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train_binary)\n",
    "        return X_resampled, y_resampled\n",
    "    else:\n",
    "        # If labels are not numeric, proceed with SMOTE without conversion\n",
    "        smote = SMOTE(sampling_strategy='auto', random_state=42)  # 'auto' adjusts the strategy based on the input data\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "        return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_variables(df_encoded, categorical_cols):\n",
    "    logging.info(\"Encoding categorical variables...\")\n",
    "    if df_encoded.empty: logging.warning(\"DataFrame is empty before encoding.\")\n",
    "    df_encoded = pd.get_dummies(df_encoded, columns=categorical_cols)\n",
    "    logging.info(\"After encoding:\")\n",
    "    logging.info(df_encoded.head())\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_numerical_features(df_encoded, numerical_cols):\n",
    "    logging.info(\"Normalizing numerical features...\")\n",
    "    if df_encoded.empty: logging.warning(\"DataFrame is empty before normalization.\")\n",
    "    scaler = StandardScaler()\n",
    "    df_encoded_copy = df_encoded.copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "    df_encoded_copy[numerical_cols] = scaler.fit_transform(df_encoded_copy[numerical_cols])\n",
    "    print(\"After normalization:\")\n",
    "    print(df_encoded_copy.head())\n",
    "    return df_encoded_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_exploration(df_encoded):\n",
    "    logging.info(\"Exploratory Data Analysis:\")\n",
    "    if df_encoded.empty: logging.warning(\"DataFrame is empty.\")\n",
    "    print(\"Dataset Information:\")\n",
    "    print(df_encoded.info())\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(df_encoded.describe())\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x='ICU', data=df_encoded)\n",
    "    plt.title('Distribution of ICU Admission')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(X_train, y_train, clf, param_grid, model_type):\n",
    "    logging.info(f\"Performing grid search for {model_type} model...\")\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=6)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    logging.info(f\"Best Parameters ({model_type}): {best_params}\")\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, model_type='xgboost', param_grid=None, selected_features=None):\n",
    "    logging.info(f\"Training {model_type.capitalize()} model (this may take a while)...\")\n",
    "    if selected_features is not None:\n",
    "        X_train = X_train[selected_features]\n",
    "    if model_type == 'xgboost':\n",
    "        clf = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
    "        default_param_grid = {\n",
    "            'n_estimators': [50, 100, 150],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'subsample': [0.8, 1.0],\n",
    "            'colsample_bytree': [0.8, 1.0],\n",
    "            'min_child_weight': [1, 3, 5]\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Supported types: 'xgboost'\")\n",
    "    if param_grid is None:\n",
    "        param_grid = default_param_grid\n",
    "    # Remove 'min_samples_leaf' and 'min_samples_split' from param_grid\n",
    "    param_grid = {key: value for key, value in param_grid.items() if key not in ['min_samples_leaf', 'min_samples_split']}\n",
    "    best_estimator = perform_grid_search(X_train, y_train, clf, param_grid, model_type)\n",
    "    return best_estimator, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, feature_names):\n",
    "    logging.info(\"Visualizing feature importance...\")\n",
    "    feature_importance = model.feature_importances_\n",
    "    sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "    sorted_feature_names = np.array(feature_names)[sorted_idx]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(feature_importance)), feature_importance[sorted_idx], align=\"center\")\n",
    "    plt.xticks(range(len(feature_importance)), sorted_feature_names, rotation=90)\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.ylabel(\"Importance\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, thresholds=[0.4, 0.5, 0.6], feature_names=None):\n",
    "    logging.info(\"Evaluating model with threshold adjustment...\")\n",
    "    best_f1_score = 0\n",
    "    best_threshold = 0.5  # Default threshold\n",
    "    for threshold in thresholds:\n",
    "        # Get predicted probabilities\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "        # Convert probabilities to binary predictions based on the threshold\n",
    "        y_pred_adjusted = (y_pred_prob > threshold).astype(int)\n",
    "        # Convert y_test to binary values (assuming it's continuous)\n",
    "        y_test_binary = (y_test > 0.5).astype(int)\n",
    "        # Calculate F1-score\n",
    "        f1 = f1_score(y_test_binary, y_pred_adjusted)\n",
    "        # Update the best threshold if current F1-score is better\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_threshold = threshold\n",
    "    # Log the best threshold\n",
    "    logging.info(f\"Best threshold for maximum F1-score: {best_threshold}\")\n",
    "    # Use the best threshold for final predictions\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred_adjusted = (y_pred_prob > best_threshold).astype(int)\n",
    "    # Print classification report and confusion matrix\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test_binary, y_pred_adjusted))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test_binary, y_pred_adjusted))\n",
    "    # Print accuracy using the threshold-adjusted predictions\n",
    "    accuracy = accuracy_score(y_test_binary, y_pred_adjusted)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    precision = precision_score(y_test_binary, y_pred_adjusted)\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    recall = recall_score(y_test_binary, y_pred_adjusted)\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    f1 = f1_score(y_test_binary, y_pred_adjusted)\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    auc_roc = roc_auc_score(y_test_binary, y_pred_prob)\n",
    "    print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "    # Plot ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test_binary, y_pred_prob)\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.show()\n",
    "    # Plot Confusion Matrix\n",
    "    cm = confusion_matrix(y_test_binary, y_pred_adjusted)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No', 'Yes'])\n",
    "    disp.plot(cmap='Blues', values_format='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    # Plot Feature Importance\n",
    "    if feature_names is not None:\n",
    "        plot_feature_importance(model, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_column_type(df_current):\n",
    "    categorical_cols = []\n",
    "    numerical_cols = []\n",
    "    for column in df_current.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df_current[column]):\n",
    "            numerical_cols.append(column)\n",
    "        else:\n",
    "            categorical_cols.append(column)\n",
    "    return categorical_cols, numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "    logging.info(\"Preprocessing data...\")\n",
    "    # Feature Engineering\n",
    "    df = feature_engineering(df)\n",
    "    # Identify categorical and numerical columns\n",
    "    categorical_cols, numerical_cols = identify_column_type(df)\n",
    "\n",
    "    # Convert the 'ICU' column to categorical\n",
    "    df.loc[:, 'ICU'] = df['ICU'].astype(int)\n",
    "    # Redefine categorical and numerical columns for the updated dataframe\n",
    "    categorical_cols_updated, numerical_cols_updated = identify_column_type(df)\n",
    "    # Encoding Categorical Variables\n",
    "    df_encoded = encode_categorical_variables(df, categorical_cols_updated)\n",
    "    # Normalizing Numerical Features\n",
    "    df_encoded = normalize_numerical_features(df_encoded, numerical_cols_updated)\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_important_features(df_encoded, n_features_to_select_range=range(1, 21), threshold=0.5):\n",
    "    logging.info(\"Identifying important features using Recursive Feature Elimination (RFE)...\")\n",
    "    # After handling class imbalance and before feature engineering, remove rows with missing values\n",
    "    categorical_cols, numerical_cols = identify_column_type(df_encoded)\n",
    "    df_no_missing = handle_missing_values(df_encoded, numerical_cols)\n",
    "    # Splitting the Data for initial training\n",
    "    X_task2_no_missing = df_no_missing.drop(['ICU'], axis=1)\n",
    "    y_task2_no_missing = df_no_missing['ICU']\n",
    "    # Convert to binary labels based on a threshold\n",
    "    y_task2_no_missing_binary = (y_task2_no_missing > threshold).astype(int)\n",
    "    X_train_no_missing_task2, X_test_no_missing_task2, y_train_no_missing_task2, y_test_no_missing_task2 = train_test_split(\n",
    "        X_task2_no_missing, y_task2_no_missing_binary, test_size=0.2, random_state=42)\n",
    "    # Handling Class Imbalance for the cleaned dataset\n",
    "    X_train_resampled_task2, y_train_resampled_task2 = handle_class_imbalance(\n",
    "        X_train_no_missing_task2, y_train_no_missing_task2)\n",
    "    # Initialize the XGBClassifier for RFE\n",
    "    clf_xgb_rfe = XGBClassifier(random_state=42)\n",
    "    # Initialize RFE with the XGBClassifier\n",
    "    rfe = RFE(estimator=clf_xgb_rfe, n_features_to_select=1)  # Start with 1 feature\n",
    "    # Evaluate performance for different numbers of features using parallelized cross-validation\n",
    "    cv_scores = []\n",
    "    with parallel_backend('loky', n_jobs=-1):  # Use all available CPUs\n",
    "        for n_features_to_select in n_features_to_select_range:\n",
    "            rfe.n_features_to_select = n_features_to_select\n",
    "            scores = cross_val_score(rfe, X_train_resampled_task2, y_train_resampled_task2, cv=5, scoring='accuracy')\n",
    "            cv_scores.append(scores.mean())\n",
    "    # Choose the number of features that maximizes the cross-validation score\n",
    "    optimal_n_features = n_features_to_select_range[cv_scores.index(max(cv_scores))]\n",
    "    # Fit RFE with the optimal number of features\n",
    "    rfe.n_features_to_select = optimal_n_features\n",
    "    rfe.fit(X_train_resampled_task2, y_train_resampled_task2)\n",
    "    # Get the selected features\n",
    "    selected_features_rfe = X_train_resampled_task2.columns[rfe.support_]\n",
    "    return selected_features_rfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Script Start</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "# Load the dataset\n",
    "data = \"COVID-Full.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(data)\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"Error: Data file '{data}' not found.\")\n",
    "    exit(1)\n",
    "except pd.errors.EmptyDataError:\n",
    "    logging.error(f\"Error: Data file '{data}' is empty.\")\n",
    "    exit(1)\n",
    "except pd.errors.ParserError:\n",
    "    logging.error(f\"Error: Unable to parse data from '{data}'. Check the file format.\")\n",
    "    exit(1)\n",
    "\n",
    "# Data Preprocessing\n",
    "df_encoded = data_preprocessing(df)\n",
    "# Identify important features\n",
    "important_features = identify_important_features(df_encoded)\n",
    "# Impute rows with missing values for important features from the original dataset\n",
    "df_cleaned = handle_missing_values(df_encoded, important_features)\n",
    "# Splitting the Data for updated training\n",
    "X_task2 = df_cleaned.drop(['ICU'], axis=1)\n",
    "y_task2 = df_cleaned['ICU']\n",
    "X_train_task2, X_test_task2, y_train_task2, y_test_task2 = train_test_split(\n",
    "    X_task2, y_task2, test_size=0.2, random_state=42)\n",
    "# Handling Class Imbalance for the updated dataset\n",
    "X_train_resampled_task2, y_train_resampled_task2 = handle_class_imbalance(X_train_task2, y_train_task2)\n",
    "# Train the XGBoost model on the updated data with selected features\n",
    "clf_xgb_tuned_task2, selected_features = train_model(\n",
    "    X_train_resampled_task2, y_train_resampled_task2, model_type='xgboost', selected_features=important_features)\n",
    "# Filter X_test_task2\n",
    "X_test_task2_filtered = X_test_task2[important_features]\n",
    "# Ensure y_test_task2 aligns with the filtered X_test_task2\n",
    "# (assuming the order of samples is the same)\n",
    "y_test_task2_filtered = y_test_task2\n",
    "# Evaluate the model\n",
    "evaluate_model(clf_xgb_tuned_task2, X_test_task2_filtered, y_test_task2_filtered, thresholds=[0.4, 0.5, 0.6], feature_names=selected_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
